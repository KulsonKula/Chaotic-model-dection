{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data=pd.read_csv(data_path)\n",
    "    X = data.iloc[: ,:-1].to_numpy()\n",
    "    Y = data['labels'].to_numpy()\n",
    "\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming load_data is a function defined elsewhere\n",
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_50.csv\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/best_optimalized.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=0,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "def create_model(trial):\n",
    "    lstm_units = trial.suggest_int('lstm_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    l1_reg = trial.suggest_float('l1_reg', 1e-5, 1e-2, log=True)\n",
    "    l2_reg = trial.suggest_float('l2_reg', 1e-5, 1e-2, log=True)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "    add_dense_before = trial.suggest_categorical('add_dense_before', [True, False])\n",
    "    add_dense_after = trial.suggest_categorical('add_dense_after', [True, False])\n",
    "    \n",
    "    if add_dense_before:\n",
    "        dense_units_before = trial.suggest_int('dense_units_before', 16, 64)\n",
    "    \n",
    "    if add_dense_after:\n",
    "        dense_units_after = trial.suggest_int('dense_units_after', 16, 64)\n",
    "\n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(x_train)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(normalizer)\n",
    "    \n",
    "    if add_dense_before:\n",
    "        model.add(layers.Dense(dense_units_before, activation='relu'))\n",
    "\n",
    "    if use_batch_norm:\n",
    "        model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.LSTM(lstm_units, activation=\"tanh\", \n",
    "                          kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    if add_dense_after:\n",
    "        model.add(layers.Dense(dense_units_after, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[checkpoint,TFKerasPruningCallback(trial, 'val_accuracy')],\n",
    "        verbose=0 \n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return val_accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "\n",
    "\n",
    "best_trial = study.best_trial\n",
    "model = create_model(best_trial)\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "model.save('best_model.h5')\n",
    "\n",
    "# Plot model architecture\n",
    "plot_file = 'model.png'\n",
    "plot_model(model, to_file=plot_file, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the model plot\n",
    "plt.figure(figsize=(10, 15))\n",
    "img = plt.imread(plot_file)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
