{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data=pd.read_csv(data_path)\n",
    "    X = data.iloc[: ,:-1].to_numpy()\n",
    "    Y = data['labels'].to_numpy()\n",
    "\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def create_compile_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7174/7174 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9910\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98970, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 88s 12ms/step - loss: 0.0372 - accuracy: 0.9910 - val_loss: 0.0381 - val_accuracy: 0.9897 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "  11/7174 [..............................] - ETA: 1:15 - loss: 0.0413 - accuracy: 0.9872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9966\n",
      "Epoch 2: val_accuracy improved from 0.98970 to 0.99603, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 96s 13ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.0178 - val_accuracy: 0.9960 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "7171/7174 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9972\n",
      "Epoch 3: val_accuracy improved from 0.99603 to 0.99825, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 110s 15ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.0097 - val_accuracy: 0.9982 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "7174/7174 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9984\n",
      "Epoch 4: val_accuracy improved from 0.99825 to 0.99887, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 161s 22ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0051 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 5: val_accuracy did not improve from 0.99887\n",
      "7174/7174 [==============================] - 165s 23ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0077 - val_accuracy: 0.9986 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "7174/7174 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9990\n",
      "Epoch 6: val_accuracy improved from 0.99887 to 0.99932, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 162s 23ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9989\n",
      "Epoch 7: val_accuracy improved from 0.99932 to 0.99943, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 117s 16ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "7174/7174 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 8: val_accuracy improved from 0.99943 to 0.99966, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 99s 14ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0020 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "7171/7174 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 9: val_accuracy did not improve from 0.99966\n",
      "7174/7174 [==============================] - 99s 14ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9996 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 10: val_accuracy improved from 0.99966 to 0.99978, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 100s 14ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0013 - val_accuracy: 0.9998 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_50.csv\")\n",
    "\n",
    "def custom_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.02))\n",
    "scheduler = LearningRateScheduler(custom_scheduler)\n",
    "\n",
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "\n",
    "model_lstm_50 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.LSTM(64, activation=\"tanh\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_50.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "model_lstm_50.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_lstm_50=model_lstm_50.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test), callbacks=[checkpoint, scheduler])\n",
    "\n",
    "# model_lstm_50.save(r\"../model/model_50.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3586/3587 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9435\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99326, saving model to ../model\\model_100.h5\n",
      "3587/3587 [==============================] - 183s 51ms/step - loss: 0.1614 - accuracy: 0.9435 - val_loss: 0.0274 - val_accuracy: 0.9933 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "   3/3587 [..............................] - ETA: 2:38 - loss: 0.0187 - accuracy: 0.9948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9948\n",
      "Epoch 2: val_accuracy improved from 0.99326 to 0.99760, saving model to ../model\\model_100.h5\n",
      "3587/3587 [==============================] - 185s 52ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.0141 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "3586/3587 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9961\n",
      "Epoch 3: val_accuracy did not improve from 0.99760\n",
      "3587/3587 [==============================] - 186s 52ms/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: 0.0161 - val_accuracy: 0.9971 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9977\n",
      "Epoch 4: val_accuracy improved from 0.99760 to 0.99807, saving model to ../model\\model_100.h5\n",
      "3587/3587 [==============================] - 186s 52ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0118 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9968\n",
      "Epoch 5: val_accuracy did not improve from 0.99807\n",
      "3587/3587 [==============================] - 219s 61ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.0135 - val_accuracy: 0.9978 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "3586/3587 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9982\n",
      "Epoch 6: val_accuracy improved from 0.99807 to 0.99876, saving model to ../model\\model_100.h5\n",
      "3587/3587 [==============================] - 244s 68ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0085 - val_accuracy: 0.9988 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9984\n",
      "Epoch 7: val_accuracy did not improve from 0.99876\n",
      "3587/3587 [==============================] - 201s 56ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.0098 - val_accuracy: 0.9979 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9984\n",
      "Epoch 8: val_accuracy improved from 0.99876 to 0.99888, saving model to ../model\\model_100.h5\n",
      "3587/3587 [==============================] - 204s 57ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.0075 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9988\n",
      "Epoch 9: val_accuracy did not improve from 0.99888\n",
      "3587/3587 [==============================] - 256s 71ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9988 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "3587/3587 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9988\n",
      "Epoch 10: val_accuracy did not improve from 0.99888\n",
      "3587/3587 [==============================] - 278s 77ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9988 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_100.csv\")\n",
    "\n",
    "model_lstm_100 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.LSTM(64, activation=\"tanh\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model_lstm_100.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_100.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "\n",
    "history_lstm_100=model_lstm_100.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test), callbacks=[checkpoint,scheduler])\n",
    "# model_lstm_100.save(r\"../model/model_100.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9194\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92518, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 270s 148ms/step - loss: 0.2332 - accuracy: 0.9194 - val_loss: 0.4087 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "   1/1794 [..............................] - ETA: 4:07 - loss: 0.4509 - accuracy: 0.9219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794/1794 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9608\n",
      "Epoch 2: val_accuracy improved from 0.92518 to 0.99042, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 249s 139ms/step - loss: 0.1556 - accuracy: 0.9608 - val_loss: 0.0585 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9820\n",
      "Epoch 3: val_accuracy did not improve from 0.99042\n",
      "1794/1794 [==============================] - 242s 135ms/step - loss: 0.0714 - accuracy: 0.9820 - val_loss: 0.0739 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9725\n",
      "Epoch 4: val_accuracy did not improve from 0.99042\n",
      "1794/1794 [==============================] - 276s 154ms/step - loss: 0.1065 - accuracy: 0.9725 - val_loss: 0.0877 - val_accuracy: 0.9769 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9618\n",
      "Epoch 5: val_accuracy did not improve from 0.99042\n",
      "1794/1794 [==============================] - 254s 142ms/step - loss: 0.1128 - accuracy: 0.9618 - val_loss: 0.1410 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9765\n",
      "Epoch 6: val_accuracy improved from 0.99042 to 0.99453, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 250s 140ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0302 - val_accuracy: 0.9945 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9751\n",
      "Epoch 7: val_accuracy improved from 0.99453 to 0.99509, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 244s 136ms/step - loss: 0.0970 - accuracy: 0.9751 - val_loss: 0.0298 - val_accuracy: 0.9951 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9966\n",
      "Epoch 8: val_accuracy improved from 0.99509 to 0.99822, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 249s 139ms/step - loss: 0.0209 - accuracy: 0.9966 - val_loss: 0.0119 - val_accuracy: 0.9982 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9846\n",
      "Epoch 9: val_accuracy improved from 0.99822 to 0.99850, saving model to ../model\\model_200.h5\n",
      "1794/1794 [==============================] - 265s 148ms/step - loss: 0.0557 - accuracy: 0.9846 - val_loss: 0.0110 - val_accuracy: 0.9985 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1794/1794 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9978\n",
      "Epoch 10: val_accuracy did not improve from 0.99850\n",
      "1794/1794 [==============================] - 247s 138ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.0172 - val_accuracy: 0.9968 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_200.csv\")\n",
    "\n",
    "model_lstm_200 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.LSTM(64, activation=\"tanh\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model_lstm_200.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_200.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "history_lstm_200=model_lstm_200.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test), callbacks=[checkpoint,scheduler])\n",
    "\n",
    "# model_lstm_200.save(r\"../model/model_200.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9924\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99588, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 83s 11ms/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.0190 - val_accuracy: 0.9959 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "  16/7174 [..............................] - ETA: 1:12 - loss: 0.0331 - accuracy: 0.9941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7171/7174 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9979\n",
      "Epoch 2: val_accuracy improved from 0.99588 to 0.99842, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 82s 11ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "7170/7174 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 3: val_accuracy improved from 0.99842 to 0.99916, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 81s 11ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7169/7174 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 4: val_accuracy did not improve from 0.99916\n",
      "7174/7174 [==============================] - 80s 11ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0041 - val_accuracy: 0.9990 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "7171/7174 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9988\n",
      "Epoch 5: val_accuracy improved from 0.99916 to 0.99954, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 80s 11ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0026 - val_accuracy: 0.9995 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_50.csv\")\n",
    "\n",
    "def custom_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.02))\n",
    "scheduler = LearningRateScheduler(custom_scheduler)\n",
    "\n",
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "\n",
    "model_lstm_50 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.LSTM(64, activation=\"tanh\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_50_test1_best.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "model_lstm_50.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_lstm_50=model_lstm_50.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), callbacks=[scheduler])\n",
    "\n",
    "model_lstm_50.save(r\"../model/model_50_test1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9909\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99499, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 94s 13ms/step - loss: 0.0400 - accuracy: 0.9909 - val_loss: 0.0263 - val_accuracy: 0.9950 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "  16/7174 [..............................] - ETA: 1:22 - loss: 0.0085 - accuracy: 0.9971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7174/7174 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 2: val_accuracy improved from 0.99499 to 0.99743, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 94s 13ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0093 - val_accuracy: 0.9974 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "7171/7174 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9985\n",
      "Epoch 3: val_accuracy improved from 0.99743 to 0.99837, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 92s 13ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0075 - val_accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9986\n",
      "Epoch 4: val_accuracy improved from 0.99837 to 0.99939, saving model to ../model\\model_50.h5\n",
      "7174/7174 [==============================] - 93s 13ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 5: val_accuracy did not improve from 0.99939\n",
      "7174/7174 [==============================] - 93s 13ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9990 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_50.csv\")\n",
    "\n",
    "def custom_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.02))\n",
    "scheduler = LearningRateScheduler(custom_scheduler)\n",
    "\n",
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "\n",
    "model_lstm_50 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.LSTM(64, activation=\"tanh\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_50_test2_best.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "model_lstm_50.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_lstm_50=model_lstm_50.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), callbacks=[scheduler])\n",
    "\n",
    "model_lstm_50.save(r\"../model/model_50_test2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9946\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99912, saving model to ../model\\model_50_test3_best.h5\n",
      "7174/7174 [==============================] - 219s 30ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0052 - val_accuracy: 0.9991 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "   7/7174 [..............................] - ETA: 3:13 - loss: 6.3609e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9989\n",
      "Epoch 2: val_accuracy improved from 0.99912 to 0.99929, saving model to ../model\\model_50_test3_best.h5\n",
      "7174/7174 [==============================] - 207s 29ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "7173/7174 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 3: val_accuracy improved from 0.99929 to 0.99943, saving model to ../model\\model_50_test3_best.h5\n",
      "7174/7174 [==============================] - 209s 29ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 4: val_accuracy improved from 0.99943 to 0.99970, saving model to ../model\\model_50_test3_best.h5\n",
      "7174/7174 [==============================] - 205s 29ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "7172/7174 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 5: val_accuracy improved from 0.99970 to 0.99975, saving model to ../model\\model_50_test3_best.h5\n",
      "7174/7174 [==============================] - 203s 28ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9997 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(\"../data/data_proccesed_50.csv\")\n",
    "\n",
    "def custom_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.02))\n",
    "scheduler = LearningRateScheduler(custom_scheduler)\n",
    "\n",
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "\n",
    "model_lstm_50 = models.Sequential([\n",
    "    layers.Input(shape=(x_train.shape[1], x_train.shape[2])), \n",
    "    normalizer,\n",
    "    layers.LSTM(64,return_sequences=True, activation=\"tanh\"),\n",
    "    layers.LSTM(32,return_sequences=True, activation=\"tanh\"),\n",
    "    layers.LSTM(16,return_sequences=False, activation=\"tanh\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r\"../model/model_50_test3_best.h5\",  \n",
    "    monitor='val_accuracy',        \n",
    "    verbose=1,                 \n",
    "    save_best_only=True,       \n",
    "    mode='max'                 \n",
    ")\n",
    "\n",
    "model_lstm_50.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_lstm_50=model_lstm_50.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), callbacks=[scheduler])\n",
    "\n",
    "model_lstm_50.save(r\"../model/model_50_test3.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
